<h3>Automated annotation</h3>

<p> This dialog contain information about the CoralNet automated annotation system. This information is summarized in our <a href="http://vimeo.com/104754418">instruction video</a> on Vimeo. For technical details refer to these two publications: <a href="http://vision.ucsd.edu/sites/default/files/automated_coral_annotation.pdf">This one</a>, and <a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130312">this one.</a></p>

<ul>
    <li><strong>Basic information</strong>
        <p> The CoralNet back-end (Robot) runs each morning 3.03 AM Pacific Central Time. CoralNet reads all confirmed annotations, and if there are new annotations, trains a new version of the Robot. The new Robot will then (re)annotate all unconfirmed images. This means that for large sources, an image may be re-annotated by several Robot versions before a human operator annotates (confirms) it. These Robot annotations can be viewed in the annotation log, which is accessible from the annotation tool. </p>

        <p> Note1: the first Robot will be trained once there are at least 5 confirmed images in the source.</p>
          <p> Note2: during periods of heavy use, the server may need 2-3 days to generate new robot versions for all sources.</p>

    </li>

    <li><strong>Robot Performance Estimation</strong>
        <p>The confirmed data (training data) is split in five equal parts. A classifier is then trained on four of the parts and evaluated on the last part. This procedure is used to generate the confusion matrices (and accuracy estimates) in the table, as well as to calibrate the <a href="http://vision.ucsd.edu/sites/default/files/automated_coral_annotation.pdf">hyper parameters</a> of the machine learning algorithm.</p>
    <p> Note: Due to the design of the performance estimation procedure, the total number of classified samples in the confusion matrices (which can be seen in the rightmost column) should be roughly 1/5 of the total number of training samples. </p> 
    </li>

    <li><strong>Robot statistics table</strong>
        <p>Once your first Robot is trained, a table will appear in this dialog. This table contains the following information for the last three Robots: 
        <ul>
            <li>#: Robot version. This is a site-wide unique Robot id number. This is generally not consecutive for a source.</li>
            <li>Date: Date this Robot version was trained. </li>
            <li>Time: Time required to train this Robot version (seconds). </li>
            <li>Samp: Number of training samples available for this Robot version. This is equal to the number of confirmed images times the number of points per image. </li>
            <li>Full: Accuracy as measured on the full label set. Accuracy is calculated as simple Accuracy (Acc), and as <a href="http://en.wikipedia.org/wiki/Cohen%27s_kappa">Cohen's Kappa (K)</a>. Clicking on any of these generates a pop-up with the confusion matrix.</li>
            <li>Func.: Accuracy as measured on the functional group level. In addition to (Acc) and (K) which are accuracies calculated on the functional group level, we also show the recommended alleviation level (ALL). This level is determined as the alleviation that results in a 5% reduction of accuracy for classifying corals versus non-corals. Clicking the ALL number produces a curve showing the trade-off between higher alleviation and accuracy. If your source doesn't contain any coral, the ALL column will say N.A. You may, however, still use the Alleviate feature.</li>
        </ul>
        You may click on any of the accuracy numbers to view the confusion matrix on the full or functional group level. These can then be downloaded for further analysis. </p>
    </li>


    <li><strong>Source specific Robots</strong>
        <p> All Robots are source-specific. This means that it will learn only from confirmed annotation <i>within</i> the source, and only annotate image in that same source. The reason for this is simple: machine learning across different sources is difficult, and it's not clear how to do this efficiently yet. </p>
    </li>
    
    <li><strong>More information on the Alleviate annotation mode</strong>
    <p>
        The CoralNet alleviate feature offers a trade-off between fully automated and fully manual annotation. This is done by auto-accepting machine annotations when they are sufficiently confident. Please refer to our <a href="https://vimeo.com/channels/coralnet/133397508"> instruction video</a> for an overview and <a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130312">this study</a> for more details.<br/><br/>
        
        This auto-acceptance happens when you enter the annotation tool for an image. Effectively, the machine's most confident points are "alleviated" from your annotation workload (for that image). Alleviated annotation decisions are treated as 'Confirmed', and are included when you export your annotations. <br/><br/>
        
        Users control this functionality by specifying the level of alleviation. For example, with 40% alleviation, the machine learning algorithm ("robot") will do 40% of the point annotations and leave the remaining 60% for the human operator. This level of alleviation is NOT per image, but the average across all remaining images. Some (easy) images may be fully alleviated, while other (harder) may have very little alleviated points. 0% alleviation corresponds to no alleviation (i.e. fully manual annotation).<br/><br/>
        
        When the first robot version is trained for your source, you can see the trade-off between the level of alleviation and the annotation accuracy. We recommend that you set the alleviation level to 0% until you have seen this trade-off curve. You can then adjust the alleviation level. <br/><br/>
        
        <a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130312">This study</a> suggests that a 5% drop is annotation accuracy has marginal (if any) impact on derived cover estimates. We therefore suggest that you set the level of alleviation corresponding to a 5% drop in accuracy.<br/><br/>

        NOTE1: The level of alleviation should not be confused with the confidence scores that are displayed during manual annotation. Once you set your desired level of alleviation, this is translated to a confidence score by the back-end, and any robot prediction above that confidence will be automatically accepted. 
        <br/><br/>

        NOTE2: Machine annotations that have <strong>not</strong> been Confirmed can optionally also be included in your export (see the 'export' page) <br/><br/>
    </p>
    </li>
</ul>
